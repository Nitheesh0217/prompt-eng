{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template Prompting\n",
    "\n",
    "Prompt Template Prompting refers to a technique where predefined templates are used to construct effective prompts that guide large language models (LLMs) to generate responses tailored to specific use cases. The templates typically contain static text combined with dynamic input variables, allowing for consistent, reusable, and customizable prompts.\n",
    "\n",
    "Prompt templates are widely used across various domains, such as:\n",
    "* **Question Generation**: Templates can generate quiz questions by filling in variables related to topics.\n",
    "* **Text Summarization**: Static instructions combined with variable documents or inputs allow flexible summarization.\n",
    "* **Coding Assistance**: Dynamic prompts help LLMs generate code snippets for different programming tasks.\n",
    "\n",
    "## References:\n",
    "\n",
    "* (OpenAI Documentation for Prompt Engineering)[https://platform.openai.com/docs/guides/prompt-engineering]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fprompt_template.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload: {'model': 'Llama-3.2-3B-Instruct', 'messages': [{'role': 'user', 'content': 'Act like you are an AI that provides clear, concise project usage instructions. Focus on how to install, configure, and run the automated GitHub markdown report system.\\nHow do I set up the automated GitHub report generator?\\nOutput only the steps in bullet points—no extra explanations or disclaimers.'}]}\n",
      "===== PROMPT TEMPLATE OUTPUT (PROJECT CONTEXT) =====\n",
      "**Setting up Automated GitHub Markdown Report Generator:**\n",
      "\n",
      "* Step 1: Install required tools:\n",
      "  • pip install reportlab\n",
      "  • git clone https://github.com/vihμένα/template-report\n",
      "  • git clone https://github.com/c_idtkiAutomate_plugin\n",
      "  • git clone https://github.com/SR/Sublime-Linter\n",
      "\n",
      "* Step 2: Configure report configuration file:\n",
      "  • Create a JSON file (e.g., \".report_config.json\") with required configuration options\n",
      "  • Configure details such as project name, branch, report title, font, and more.\n",
      "\n",
      "* Step 3: Set up GitHub repository fork:\n",
      "  • Fork a personal GitHub repository\n",
      "  • Clone the repository to local machine\n",
      "  • Install repository dependencies\n",
      "\n",
      "* Step 4: Configure automated report generation script:\n",
      "  • Create a Python script to read configuration file and generate reports\n",
      "  • Connect to GitHub API to retrieve repository data\n",
      "  • Use ReportLab to generate markdown reports\n",
      "\n",
      "* Step 5: Schedule report generation:\n",
      "  • Use GitHub Actions or a cron job to run the script at regular intervals\n",
      "  • Configure trigger settings to ensure seamless report updating\n",
      "\n",
      "* Step 6: Integrate reports with GitHub repository:\n",
      "  • Use a GitHub Action workflow to deploy generated reports\n",
      "  • Create a pull_request or issue to trigger automated updates\n",
      "\n",
      "Time taken: 2.317s\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "## PROMPT TEMPLATE PROMPTING (PROJECT CONTEXT)\n",
    "############################################################\n",
    "\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Simulate an inbound user/system request\n",
    "# e.g., user wants instructions on setting up the project environment\n",
    "MESSAGE = \"How do I set up the automated GitHub report generator?\"\n",
    "\n",
    "#### (2) Prompt Templates for Workflow Orchestration\n",
    "TEMPLATE_BEFORE = (\n",
    "    \"Act like you are an AI that provides clear, concise project usage instructions. \"\n",
    "    \"Focus on how to install, configure, and run the automated GitHub markdown report system.\"\n",
    ")\n",
    "TEMPLATE_AFTER = \"Output only the steps in bullet points—no extra explanations or disclaimers.\"\n",
    "\n",
    "PROMPT = f\"{TEMPLATE_BEFORE}\\n{MESSAGE}\\n{TEMPLATE_AFTER}\"\n",
    "\n",
    "#### (3) Configure the Model request\n",
    "payload = create_payload(\n",
    "    target=\"open-webui\",            # or 'open-webui', depending on your backend\n",
    "    model=\"Llama-3.2-3B-Instruct\",    # Example model; adjust as needed\n",
    "    prompt=PROMPT,\n",
    "    temperature=1.0,\n",
    "    num_ctx=100,\n",
    "    num_predict=100\n",
    ")\n",
    "\n",
    "# 4) Send the request to the model\n",
    "time_taken, template_response = model_req(payload=payload)\n",
    "\n",
    "# 5) Display the response\n",
    "print(\"===== PROMPT TEMPLATE OUTPUT (PROJECT CONTEXT) =====\")\n",
    "print(template_response)\n",
    "if time_taken:\n",
    "    print(f\"\\nTime taken: {time_taken}s\")\n",
    "\n",
    "# 6) (Optional) Log the result for future reference\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "log_entry = [\n",
    "    datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"prompt_template_project\",\n",
    "    \"llama3.2:latest\",\n",
    "    1.0,\n",
    "    time_taken,\n",
    "    template_response.replace(\"\\n\", \"\\\\n\")\n",
    "]\n",
    "\n",
    "with open(\"data/prompt_template_logs.csv\", \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(log_entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
