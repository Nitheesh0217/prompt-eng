{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Consistency Prompting\n",
    "\n",
    "One of the more advanced techniques in prompt engineering is self-consistency, introduced by `Wang et al. (2022)`. \n",
    "\n",
    "This method seeks to improve upon the traditional greedy decoding typically used in chain-of-thought (CoT) prompting. \n",
    "\n",
    "The core concept involves sampling multiple diverse reasoning paths through few-shot CoT and leveraging these variations to determine the most consistent answer. The technique  enhances the effectiveness of CoT prompting, particularly for tasks requiring arithmetic and commonsense reasoning.\n",
    "\n",
    "## References:\n",
    "* [Wang et al. (2022)](https://arxiv.org/abs/2203.11171)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fself_consistency.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload: {'model': 'qwen2', 'messages': [{'role': 'user', 'content': '\\nYou are an advanced AI-driven technical writing system tasked with generating a **fully structured, high-quality, and professional technical report** in Markdown format. Your primary objective is to **refine and finalize a comprehensive project report** with a particular emphasis on the **\\'Results & Evaluation\\'** section. \\n\\nWhile the **main goal** is to ensure that the \\'Results & Evaluation\\' section is the most insightful, technically sound, and well-structured, you must also maintain **a professional and logically coherent structure** across all preceding sections, including:\\n- **Project Overview** (Concise introduction to the project)\\n- **Data & Methodologies** (Thorough explanation of data collection, preprocessing, and analytical techniques)\\n- **Results & Evaluation** (Detailed insights, performance metrics, visualizations, and structured technical analysis)\\n\\nThe **final output** must be a **refined, high-quality, and structured Markdown-formatted report** that effectively conveys all essential information, ensuring seamless readability, technical precision, and a structured presentation.\\n\\n---\\n\\n## **Guidelines for Refinement**\\n\\n### **1. Maintain Professional Quality Across All Sections**\\n- **Project Overview:** Ensure clarity, conciseness, and strong introduction of key objectives.\\n- **Data & Methodologies:** Present structured explanations of data sources, preprocessing, and analytical techniques.\\n- **Results & Evaluation:** Provide detailed insights, structured performance analysis, and well-integrated code blocks.\\n\\n### **2. Generate & Compare Multiple Versions of \\'Results & Evaluation\\'**\\n- Generate **three distinct versions** of the \\'Results & Evaluation\\' section, each varying in structure, depth, and formatting.\\n- Each version must contain:\\n  - **Results Summary:** Main findings, trends, and anomalies.\\n  - **Evaluation Metrics:** Accuracy, precision, recall, F1-score, RMSE, etc.\\n  - **Data Visualizations:** Tables, figures, and structured charts.\\n  - **Code Blocks:** Performance analysis and metric computation.\\n\\n### **3. Select and Refine the Best Version**\\n- Compare the versions using these criteria:\\n  - **Clarity & Readability:** Structured and easy to comprehend.\\n  - **Comprehensiveness:** Coverage of all relevant findings.\\n  - **Logical Flow:** Smooth transitions from results to evaluation.\\n  - **Technical Accuracy:** Correct calculations, visualizations, and justifications.\\n- Select the **best version** and refine it to meet the highest professional standards.\\n\\n### **4. Apply Final Refinements to the Entire Report**\\n- Ensure the **Project Overview** and **Data & Methodologies** sections are logically structured and polished.\\n- Format the report with:\\n  - **Proper Markdown headings, bullet points, structured tables, and code blocks.**\\n  - **Consistent, structured, and professional content presentation.**\\n\\n---\\n\\n## **Final Output Requirements**\\n\\nGenerate a **fully structured and professional final report** in Markdown format with:\\n- **A well-structured Project Overview** that provides context and introduces key objectives.\\n- **A professionally refined Data & Methodologies section** that aligns with findings in \\'Results & Evaluation\\'.\\n- **The most polished \\'Results & Evaluation\\' section**, integrating the strongest aspects of the different candidate versions.\\n- **Properly formatted code blocks and visual elements** for readability and technical precision.\\n\\n### **Final Deliverables:**\\n- The **full project report**, ensuring a **highly polished \\'Results & Evaluation\\'** while maintaining professional quality across all preceding sections.\\n- **Clear Markdown formatting** with structured documentation, tables, figures, and code blocks.\\n- **Seamless logical flow** between all sections, ensuring high readability and comprehension.\\n\\n---\\n\\n## **Task Directive**\\n\\nYour task is to **generate the full project report**, ensuring **all sections meet professional documentation standards**, with an explicit focus on refining and finalizing the \\'Results & Evaluation\\' section to the highest level of quality.\\n\\n**Produce a final, fully polished Markdown-formatted report that aligns with professional and industry standards.**\\n\\n\\nProject Report: Financial Literacy Research Using Machine Learning\\\\n===========================================================\\\\n\\\\nOverview\\\\n--------\\\\n\\\\nThis project aims to develop a predictive model using machine learning algorithms that accurately classifies individuals based on their level of financial literacy and predicts the risk levels associated with poor financial decisions.\\\\n\\\\n### Project Title: Research on Financial Literacy Using Machine Learning\\\\n\\\\n### Problem Statement: \\\\nMany individuals lack the fundamental knowledge and skills necessary for making informed financial decisions. This lack of understanding can lead to potential financial instability and vulnerability, posing significant risks in personal finance management.\\\\n\\\\n### Goal: \\\\nTo develop a predictive model using machine learning algorithms that accurately classifies individuals based on their level of financial literacy and predicts the risk levels associated with poor financial decisions.\\\\n\\\\n### Key Objectives:\\\\n\\\\n1. **Data Gathering and Curation:** Gather comprehensive datasets that include demographic information, socioeconomic factors, and assessments of financial knowledge.\\\\n2. **Algorithm Development:** Employ supervised learning methods to build a predictive model capable of identifying individuals with varying degrees of financial literacy.\\\\n3. **Feature Analysis:** Identify the most influential features contributing to the prediction accuracy and understand their significance in relation to financial literacy.\\\\n\\\\n### Scope:\\\\nThe research will focus on a specific population group (e.g., young adults, low-income communities) as the primary data source. The scope does not include developing a fully deployed application or intervention program.\\\\n\\\\nMethodology\\\\n------------\\\\n\\\\n### Data & Methods\\\\n\\\\n#### **Data Sources**\\\\n\\\\n* Utilize publicly available datasets containing demographic information, socioeconomic indicators such as income, and education level, along with financial literacy assessments.\\\\n* **Example Datasets:** National Financial Capability Study (NFCS) by the Bureau of Labor Statistics, Survey of Consumer Finances (SCF) by Federal Reserve Board\\\\n\\\\n#### **Data Preprocessing**\\\\n\\\\n* Prepare the data for machine learning algorithms by:\\\\n\\t+ Encoding categorical variables using techniques such as one-hot encoding or label encoding.\\\\n\\t+ Handling missing values through imputation methods like mean, median, or mode imputation.\\\\n\\t+ Creating new features based on domain expertise.\\\\n\\\\n## Code Snippets\\\\n```python\\\\n# Import necessary libraries (e.g., pandas, scikit-learn)\\\\nimport pandas as pd\\\\nfrom sklearn.model_selection import train_test_split\\\\n\\\\n# Load and preprocess the dataset using pandas\\\\ndata = pd.read_csv(\\'financial_literacy_data.csv\\')\\\\n\\\\n# Define features (X) and target variable (y)\\\\nfeatures = [\\'age\\', \\'education_level\\', \\'income\\']\\\\ntarget = \\'financial_literacy_score\\'\\\\n\\\\nX = data[features]\\\\ny = data[target]\\\\n\\\\n# Splitting the dataset into training and testing sets\\\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\\\\n```\\\\nResults & Evaluation\\\\n-------------------\\\\n\\\\n### Results Overview\\\\n\\\\n* **Accuracy**: Percentage of correctly classified instances across different financial literacy levels.\\\\n* **Precision**: Model\\'s ability to accurately predict high financial literacy cases.\\\\n* **Recall**: Model\\'s capability to capture all positive (highly literate) cases.\\\\n* **F1-Score**: Balanced precision and recall for a comprehensive performance metric.\\\\n\\\\n### Evaluation Metrics\\\\n\\\\n```python\\\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\\\\n\\\\n# Function to evaluate model performance\\\\ndef evaluate_model(model):\\\\n    predictions = model.predict(X_test)\\\\n    print(\"Accuracy:\", accuracy_score(y_test, predictions))\\\\n    print(\"Precision:\", precision_score(y_test, predictions))\\\\n    print(\"Recall:\", recall_score(y_test, predictions))\\\\n    print(\"F1-Score:\", f1_score(y_test, predictions))\\\\n\\\\n# Example evaluation with trained model\\\\nevaluate_model(trained_model)\\\\n```\\\\n\\\\nDiscussion & Conclusion\\\\n--------------------\\\\n\\\\n### Discussion\\\\n\\\\n* Interpret the results of the predictive model and discuss the most influential factors contributing to financial literacy.\\\\n* Analyze potential limitations of the model that may affect its accuracy or generalizability.\\\\n\\\\n### Conclusion\\\\nSummarize key insights gained from the research on financial literacy drivers and propose future directions for addressing educational gaps through tailored interventions based on the identified risk factors.\\\\n\\\\nAppendix/Additional Resources\\\\n-------------------------------\\\\n\\\\n### Supporting Code\\\\n\\\\n```python\\\\n# Additional code for feature importance analysis using permutation importance\\\\nfrom sklearn.inspection import permutation_importance\\\\n\\\\ndef permutation_importance_analysis(model, X_test):\\\\n    result = permutation_importance(model, X_test, y_test)\\\\n    print(result.importances_mean)\\\\n\\\\n# Example usage with trained model\\\\npermutation_importance_analysis(trained_model, X_test)\\\\n```\\\\n\\\\n### Data Sources\\\\n\\\\n* **Dataset 1:** National Financial Capability Study (NFCS) by the Bureau of Labor Statistics. Accessible at [BLS.gov](https://www.bls.gov/data/).\\\\n* **Dataset 2:** Survey of Consumer Finances (SCF) by Federal Reserve Board. Accessible at [FRB.org](https://www.federalreserve.gov/publications/).\\\\n\\\\nThese resources provide comprehensive datasets that include detailed information on demographics, financial literacy scores, and socioeconomic indicators necessary for conducting the research.\\n\\n'}]}\n",
      "Payload: {'model': 'qwen2', 'messages': [{'role': 'user', 'content': '\\nYou are an advanced AI-driven technical writing system tasked with generating a **fully structured, high-quality, and professional technical report** in Markdown format. Your primary objective is to **refine and finalize a comprehensive project report** with a particular emphasis on the **\\'Results & Evaluation\\'** section. \\n\\nWhile the **main goal** is to ensure that the \\'Results & Evaluation\\' section is the most insightful, technically sound, and well-structured, you must also maintain **a professional and logically coherent structure** across all preceding sections, including:\\n- **Project Overview** (Concise introduction to the project)\\n- **Data & Methodologies** (Thorough explanation of data collection, preprocessing, and analytical techniques)\\n- **Results & Evaluation** (Detailed insights, performance metrics, visualizations, and structured technical analysis)\\n\\nThe **final output** must be a **refined, high-quality, and structured Markdown-formatted report** that effectively conveys all essential information, ensuring seamless readability, technical precision, and a structured presentation.\\n\\n---\\n\\n## **Guidelines for Refinement**\\n\\n### **1. Maintain Professional Quality Across All Sections**\\n- **Project Overview:** Ensure clarity, conciseness, and strong introduction of key objectives.\\n- **Data & Methodologies:** Present structured explanations of data sources, preprocessing, and analytical techniques.\\n- **Results & Evaluation:** Provide detailed insights, structured performance analysis, and well-integrated code blocks.\\n\\n### **2. Generate & Compare Multiple Versions of \\'Results & Evaluation\\'**\\n- Generate **three distinct versions** of the \\'Results & Evaluation\\' section, each varying in structure, depth, and formatting.\\n- Each version must contain:\\n  - **Results Summary:** Main findings, trends, and anomalies.\\n  - **Evaluation Metrics:** Accuracy, precision, recall, F1-score, RMSE, etc.\\n  - **Data Visualizations:** Tables, figures, and structured charts.\\n  - **Code Blocks:** Performance analysis and metric computation.\\n\\n### **3. Select and Refine the Best Version**\\n- Compare the versions using these criteria:\\n  - **Clarity & Readability:** Structured and easy to comprehend.\\n  - **Comprehensiveness:** Coverage of all relevant findings.\\n  - **Logical Flow:** Smooth transitions from results to evaluation.\\n  - **Technical Accuracy:** Correct calculations, visualizations, and justifications.\\n- Select the **best version** and refine it to meet the highest professional standards.\\n\\n### **4. Apply Final Refinements to the Entire Report**\\n- Ensure the **Project Overview** and **Data & Methodologies** sections are logically structured and polished.\\n- Format the report with:\\n  - **Proper Markdown headings, bullet points, structured tables, and code blocks.**\\n  - **Consistent, structured, and professional content presentation.**\\n\\n---\\n\\n## **Final Output Requirements**\\n\\nGenerate a **fully structured and professional final report** in Markdown format with:\\n- **A well-structured Project Overview** that provides context and introduces key objectives.\\n- **A professionally refined Data & Methodologies section** that aligns with findings in \\'Results & Evaluation\\'.\\n- **The most polished \\'Results & Evaluation\\' section**, integrating the strongest aspects of the different candidate versions.\\n- **Properly formatted code blocks and visual elements** for readability and technical precision.\\n\\n### **Final Deliverables:**\\n- The **full project report**, ensuring a **highly polished \\'Results & Evaluation\\'** while maintaining professional quality across all preceding sections.\\n- **Clear Markdown formatting** with structured documentation, tables, figures, and code blocks.\\n- **Seamless logical flow** between all sections, ensuring high readability and comprehension.\\n\\n---\\n\\n## **Task Directive**\\n\\nYour task is to **generate the full project report**, ensuring **all sections meet professional documentation standards**, with an explicit focus on refining and finalizing the \\'Results & Evaluation\\' section to the highest level of quality.\\n\\n**Produce a final, fully polished Markdown-formatted report that aligns with professional and industry standards.**\\n\\n\\nProject Report: Financial Literacy Research Using Machine Learning\\\\n===========================================================\\\\n\\\\nOverview\\\\n--------\\\\n\\\\nThis project aims to develop a predictive model using machine learning algorithms that accurately classifies individuals based on their level of financial literacy and predicts the risk levels associated with poor financial decisions.\\\\n\\\\n### Project Title: Research on Financial Literacy Using Machine Learning\\\\n\\\\n### Problem Statement: \\\\nMany individuals lack the fundamental knowledge and skills necessary for making informed financial decisions. This lack of understanding can lead to potential financial instability and vulnerability, posing significant risks in personal finance management.\\\\n\\\\n### Goal: \\\\nTo develop a predictive model using machine learning algorithms that accurately classifies individuals based on their level of financial literacy and predicts the risk levels associated with poor financial decisions.\\\\n\\\\n### Key Objectives:\\\\n\\\\n1. **Data Gathering and Curation:** Gather comprehensive datasets that include demographic information, socioeconomic factors, and assessments of financial knowledge.\\\\n2. **Algorithm Development:** Employ supervised learning methods to build a predictive model capable of identifying individuals with varying degrees of financial literacy.\\\\n3. **Feature Analysis:** Identify the most influential features contributing to the prediction accuracy and understand their significance in relation to financial literacy.\\\\n\\\\n### Scope:\\\\nThe research will focus on a specific population group (e.g., young adults, low-income communities) as the primary data source. The scope does not include developing a fully deployed application or intervention program.\\\\n\\\\nMethodology\\\\n------------\\\\n\\\\n### Data & Methods\\\\n\\\\n#### **Data Sources**\\\\n\\\\n* Utilize publicly available datasets containing demographic information, socioeconomic indicators such as income, and education level, along with financial literacy assessments.\\\\n* **Example Datasets:** National Financial Capability Study (NFCS) by the Bureau of Labor Statistics, Survey of Consumer Finances (SCF) by Federal Reserve Board\\\\n\\\\n#### **Data Preprocessing**\\\\n\\\\n* Prepare the data for machine learning algorithms by:\\\\n\\t+ Encoding categorical variables using techniques such as one-hot encoding or label encoding.\\\\n\\t+ Handling missing values through imputation methods like mean, median, or mode imputation.\\\\n\\t+ Creating new features based on domain expertise.\\\\n\\\\n## Code Snippets\\\\n```python\\\\n# Import necessary libraries (e.g., pandas, scikit-learn)\\\\nimport pandas as pd\\\\nfrom sklearn.model_selection import train_test_split\\\\n\\\\n# Load and preprocess the dataset using pandas\\\\ndata = pd.read_csv(\\'financial_literacy_data.csv\\')\\\\n\\\\n# Define features (X) and target variable (y)\\\\nfeatures = [\\'age\\', \\'education_level\\', \\'income\\']\\\\ntarget = \\'financial_literacy_score\\'\\\\n\\\\nX = data[features]\\\\ny = data[target]\\\\n\\\\n# Splitting the dataset into training and testing sets\\\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\\\\n```\\\\nResults & Evaluation\\\\n-------------------\\\\n\\\\n### Results Overview\\\\n\\\\n* **Accuracy**: Percentage of correctly classified instances across different financial literacy levels.\\\\n* **Precision**: Model\\'s ability to accurately predict high financial literacy cases.\\\\n* **Recall**: Model\\'s capability to capture all positive (highly literate) cases.\\\\n* **F1-Score**: Balanced precision and recall for a comprehensive performance metric.\\\\n\\\\n### Evaluation Metrics\\\\n\\\\n```python\\\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\\\\n\\\\n# Function to evaluate model performance\\\\ndef evaluate_model(model):\\\\n    predictions = model.predict(X_test)\\\\n    print(\"Accuracy:\", accuracy_score(y_test, predictions))\\\\n    print(\"Precision:\", precision_score(y_test, predictions))\\\\n    print(\"Recall:\", recall_score(y_test, predictions))\\\\n    print(\"F1-Score:\", f1_score(y_test, predictions))\\\\n\\\\n# Example evaluation with trained model\\\\nevaluate_model(trained_model)\\\\n```\\\\n\\\\nDiscussion & Conclusion\\\\n--------------------\\\\n\\\\n### Discussion\\\\n\\\\n* Interpret the results of the predictive model and discuss the most influential factors contributing to financial literacy.\\\\n* Analyze potential limitations of the model that may affect its accuracy or generalizability.\\\\n\\\\n### Conclusion\\\\nSummarize key insights gained from the research on financial literacy drivers and propose future directions for addressing educational gaps through tailored interventions based on the identified risk factors.\\\\n\\\\nAppendix/Additional Resources\\\\n-------------------------------\\\\n\\\\n### Supporting Code\\\\n\\\\n```python\\\\n# Additional code for feature importance analysis using permutation importance\\\\nfrom sklearn.inspection import permutation_importance\\\\n\\\\ndef permutation_importance_analysis(model, X_test):\\\\n    result = permutation_importance(model, X_test, y_test)\\\\n    print(result.importances_mean)\\\\n\\\\n# Example usage with trained model\\\\npermutation_importance_analysis(trained_model, X_test)\\\\n```\\\\n\\\\n### Data Sources\\\\n\\\\n* **Dataset 1:** National Financial Capability Study (NFCS) by the Bureau of Labor Statistics. Accessible at [BLS.gov](https://www.bls.gov/data/).\\\\n* **Dataset 2:** Survey of Consumer Finances (SCF) by Federal Reserve Board. Accessible at [FRB.org](https://www.federalreserve.gov/publications/).\\\\n\\\\nThese resources provide comprehensive datasets that include detailed information on demographics, financial literacy scores, and socioeconomic indicators necessary for conducting the research.\\n\\n'}]}\n",
      "Payload: {'model': 'qwen2', 'messages': [{'role': 'user', 'content': '\\nYou are an advanced AI-driven technical writing system tasked with generating a **fully structured, high-quality, and professional technical report** in Markdown format. Your primary objective is to **refine and finalize a comprehensive project report** with a particular emphasis on the **\\'Results & Evaluation\\'** section. \\n\\nWhile the **main goal** is to ensure that the \\'Results & Evaluation\\' section is the most insightful, technically sound, and well-structured, you must also maintain **a professional and logically coherent structure** across all preceding sections, including:\\n- **Project Overview** (Concise introduction to the project)\\n- **Data & Methodologies** (Thorough explanation of data collection, preprocessing, and analytical techniques)\\n- **Results & Evaluation** (Detailed insights, performance metrics, visualizations, and structured technical analysis)\\n\\nThe **final output** must be a **refined, high-quality, and structured Markdown-formatted report** that effectively conveys all essential information, ensuring seamless readability, technical precision, and a structured presentation.\\n\\n---\\n\\n## **Guidelines for Refinement**\\n\\n### **1. Maintain Professional Quality Across All Sections**\\n- **Project Overview:** Ensure clarity, conciseness, and strong introduction of key objectives.\\n- **Data & Methodologies:** Present structured explanations of data sources, preprocessing, and analytical techniques.\\n- **Results & Evaluation:** Provide detailed insights, structured performance analysis, and well-integrated code blocks.\\n\\n### **2. Generate & Compare Multiple Versions of \\'Results & Evaluation\\'**\\n- Generate **three distinct versions** of the \\'Results & Evaluation\\' section, each varying in structure, depth, and formatting.\\n- Each version must contain:\\n  - **Results Summary:** Main findings, trends, and anomalies.\\n  - **Evaluation Metrics:** Accuracy, precision, recall, F1-score, RMSE, etc.\\n  - **Data Visualizations:** Tables, figures, and structured charts.\\n  - **Code Blocks:** Performance analysis and metric computation.\\n\\n### **3. Select and Refine the Best Version**\\n- Compare the versions using these criteria:\\n  - **Clarity & Readability:** Structured and easy to comprehend.\\n  - **Comprehensiveness:** Coverage of all relevant findings.\\n  - **Logical Flow:** Smooth transitions from results to evaluation.\\n  - **Technical Accuracy:** Correct calculations, visualizations, and justifications.\\n- Select the **best version** and refine it to meet the highest professional standards.\\n\\n### **4. Apply Final Refinements to the Entire Report**\\n- Ensure the **Project Overview** and **Data & Methodologies** sections are logically structured and polished.\\n- Format the report with:\\n  - **Proper Markdown headings, bullet points, structured tables, and code blocks.**\\n  - **Consistent, structured, and professional content presentation.**\\n\\n---\\n\\n## **Final Output Requirements**\\n\\nGenerate a **fully structured and professional final report** in Markdown format with:\\n- **A well-structured Project Overview** that provides context and introduces key objectives.\\n- **A professionally refined Data & Methodologies section** that aligns with findings in \\'Results & Evaluation\\'.\\n- **The most polished \\'Results & Evaluation\\' section**, integrating the strongest aspects of the different candidate versions.\\n- **Properly formatted code blocks and visual elements** for readability and technical precision.\\n\\n### **Final Deliverables:**\\n- The **full project report**, ensuring a **highly polished \\'Results & Evaluation\\'** while maintaining professional quality across all preceding sections.\\n- **Clear Markdown formatting** with structured documentation, tables, figures, and code blocks.\\n- **Seamless logical flow** between all sections, ensuring high readability and comprehension.\\n\\n---\\n\\n## **Task Directive**\\n\\nYour task is to **generate the full project report**, ensuring **all sections meet professional documentation standards**, with an explicit focus on refining and finalizing the \\'Results & Evaluation\\' section to the highest level of quality.\\n\\n**Produce a final, fully polished Markdown-formatted report that aligns with professional and industry standards.**\\n\\n\\nProject Report: Financial Literacy Research Using Machine Learning\\\\n===========================================================\\\\n\\\\nOverview\\\\n--------\\\\n\\\\nThis project aims to develop a predictive model using machine learning algorithms that accurately classifies individuals based on their level of financial literacy and predicts the risk levels associated with poor financial decisions.\\\\n\\\\n### Project Title: Research on Financial Literacy Using Machine Learning\\\\n\\\\n### Problem Statement: \\\\nMany individuals lack the fundamental knowledge and skills necessary for making informed financial decisions. This lack of understanding can lead to potential financial instability and vulnerability, posing significant risks in personal finance management.\\\\n\\\\n### Goal: \\\\nTo develop a predictive model using machine learning algorithms that accurately classifies individuals based on their level of financial literacy and predicts the risk levels associated with poor financial decisions.\\\\n\\\\n### Key Objectives:\\\\n\\\\n1. **Data Gathering and Curation:** Gather comprehensive datasets that include demographic information, socioeconomic factors, and assessments of financial knowledge.\\\\n2. **Algorithm Development:** Employ supervised learning methods to build a predictive model capable of identifying individuals with varying degrees of financial literacy.\\\\n3. **Feature Analysis:** Identify the most influential features contributing to the prediction accuracy and understand their significance in relation to financial literacy.\\\\n\\\\n### Scope:\\\\nThe research will focus on a specific population group (e.g., young adults, low-income communities) as the primary data source. The scope does not include developing a fully deployed application or intervention program.\\\\n\\\\nMethodology\\\\n------------\\\\n\\\\n### Data & Methods\\\\n\\\\n#### **Data Sources**\\\\n\\\\n* Utilize publicly available datasets containing demographic information, socioeconomic indicators such as income, and education level, along with financial literacy assessments.\\\\n* **Example Datasets:** National Financial Capability Study (NFCS) by the Bureau of Labor Statistics, Survey of Consumer Finances (SCF) by Federal Reserve Board\\\\n\\\\n#### **Data Preprocessing**\\\\n\\\\n* Prepare the data for machine learning algorithms by:\\\\n\\t+ Encoding categorical variables using techniques such as one-hot encoding or label encoding.\\\\n\\t+ Handling missing values through imputation methods like mean, median, or mode imputation.\\\\n\\t+ Creating new features based on domain expertise.\\\\n\\\\n## Code Snippets\\\\n```python\\\\n# Import necessary libraries (e.g., pandas, scikit-learn)\\\\nimport pandas as pd\\\\nfrom sklearn.model_selection import train_test_split\\\\n\\\\n# Load and preprocess the dataset using pandas\\\\ndata = pd.read_csv(\\'financial_literacy_data.csv\\')\\\\n\\\\n# Define features (X) and target variable (y)\\\\nfeatures = [\\'age\\', \\'education_level\\', \\'income\\']\\\\ntarget = \\'financial_literacy_score\\'\\\\n\\\\nX = data[features]\\\\ny = data[target]\\\\n\\\\n# Splitting the dataset into training and testing sets\\\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\\\\n```\\\\nResults & Evaluation\\\\n-------------------\\\\n\\\\n### Results Overview\\\\n\\\\n* **Accuracy**: Percentage of correctly classified instances across different financial literacy levels.\\\\n* **Precision**: Model\\'s ability to accurately predict high financial literacy cases.\\\\n* **Recall**: Model\\'s capability to capture all positive (highly literate) cases.\\\\n* **F1-Score**: Balanced precision and recall for a comprehensive performance metric.\\\\n\\\\n### Evaluation Metrics\\\\n\\\\n```python\\\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\\\\n\\\\n# Function to evaluate model performance\\\\ndef evaluate_model(model):\\\\n    predictions = model.predict(X_test)\\\\n    print(\"Accuracy:\", accuracy_score(y_test, predictions))\\\\n    print(\"Precision:\", precision_score(y_test, predictions))\\\\n    print(\"Recall:\", recall_score(y_test, predictions))\\\\n    print(\"F1-Score:\", f1_score(y_test, predictions))\\\\n\\\\n# Example evaluation with trained model\\\\nevaluate_model(trained_model)\\\\n```\\\\n\\\\nDiscussion & Conclusion\\\\n--------------------\\\\n\\\\n### Discussion\\\\n\\\\n* Interpret the results of the predictive model and discuss the most influential factors contributing to financial literacy.\\\\n* Analyze potential limitations of the model that may affect its accuracy or generalizability.\\\\n\\\\n### Conclusion\\\\nSummarize key insights gained from the research on financial literacy drivers and propose future directions for addressing educational gaps through tailored interventions based on the identified risk factors.\\\\n\\\\nAppendix/Additional Resources\\\\n-------------------------------\\\\n\\\\n### Supporting Code\\\\n\\\\n```python\\\\n# Additional code for feature importance analysis using permutation importance\\\\nfrom sklearn.inspection import permutation_importance\\\\n\\\\ndef permutation_importance_analysis(model, X_test):\\\\n    result = permutation_importance(model, X_test, y_test)\\\\n    print(result.importances_mean)\\\\n\\\\n# Example usage with trained model\\\\npermutation_importance_analysis(trained_model, X_test)\\\\n```\\\\n\\\\n### Data Sources\\\\n\\\\n* **Dataset 1:** National Financial Capability Study (NFCS) by the Bureau of Labor Statistics. Accessible at [BLS.gov](https://www.bls.gov/data/).\\\\n* **Dataset 2:** Survey of Consumer Finances (SCF) by Federal Reserve Board. Accessible at [FRB.org](https://www.federalreserve.gov/publications/).\\\\n\\\\nThese resources provide comprehensive datasets that include detailed information on demographics, financial literacy scores, and socioeconomic indicators necessary for conducting the research.\\n\\n'}]}\n",
      "Payload: {'model': 'qwen2', 'messages': [{'role': 'user', 'content': 'Below are several candidate outputs for the Project Overview:\\n\\n---\\nSolution 1 (temp=0.77):\\n# Financial Literacy Research Using Machine Learning\\n\\n## Overview\\n\\nThe primary goal of this project is to develop a predictive model using machine learning algorithms aimed at identifying individuals with varying degrees of financial literacy and assessing their risk levels associated with poor financial decisions. The focus here is on understanding how different demographic, socioeconomic factors correlate with financial knowledge.\\n\\n### Project Title: **Research on Financial Literacy Using Machine Learning**\\n\\n### Problem Statement\\n\\nMany individuals lack the fundamental skills necessary for making informed financial decisions, which can lead to potential financial instability and difficulties in managing personal finances effectively. This project aims to explore these issues through data-driven insights.\\n\\n### Scope\\n\\nThe research focuses specifically on young adults from low-income communities as primary sources of data. The scope does not extend to developing a comprehensive intervention program or an application based on the findings; rather, it prioritizes understanding financial literacy drivers and assessing predictive models.\\n\\n## Methodology\\n\\n### Data & Methods\\n\\n#### **Data Sources**\\n\\n- Utilizing public datasets containing demographic information such as age, education level, income.\\n- Public data from:\\n    - National Financial Capability Study (NFCS) by Bureau of Labor Statistics\\n    - Survey of Consumer Finances (SCF) by Federal Reserve Board\\n\\n#### **Data Preprocessing**\\n\\n- **Encoding and Handling**: Categorical variables are encoded using techniques like one-hot encoding. Missing values in datasets are handled through imputation methods such as mean, median, or mode.\\n- **Feature Engineering**: Creation of new features based on domain expertise to enhance model performance.\\n\\n## Code Snippets\\n\\n```python\\n# Import necessary libraries for data handling and machine learning models\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import LabelEncoder\\n\\n# Load dataset using pandas dataframe library\\ndata = pd.read_csv(\\'financial_literacy_data.csv\\')\\n\\n# Define feature variables (X) and target variable (y)\\nfeatures = [\\'age\\', \\'education_level\\', \\'income\\']\\ntarget = \\'financial_literacy_score\\'\\n\\n# Encoding categorical features for better model performance\\nle = LabelEncoder()\\nfor column in data.select_dtypes(include=[\\'object\\']).columns:\\n    data[column] = le.fit_transform(data[column])\\n\\nX = data[features]\\ny = data[target]\\n\\n# Split the dataset into training and testing subsets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\\n```\\n\\n## Results & Evaluation\\n\\n### Results Overview\\n\\n- **Accuracy**: The model\\'s overall correctness in predicting financial literacy levels.\\n- **Precision**: Precision measures the modelâ€™s ability to correctly identify individuals with high financial literacy accurately.\\n- **Recall**: Recall indicates how well the model captures all cases of high financial literacy.\\n- **F1-Score**: A balanced metric between precision and recall, indicating the model\\'s overall effectiveness.\\n\\n### Evaluation Metrics\\n\\n```python\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\\n\\n# Function to evaluate model performance metrics\\ndef assess_model_performance(model):\\n    predictions = model.predict(X_test)\\n    print(\"Accuracy:\", accuracy_score(y_test, predictions))\\n    print(\"Precision:\", precision_score(y_test, predictions, average=\\'weighted\\'))\\n    print(\"Recall:\", recall_score(y_test, predictions, average=\\'weighted\\'))\\n    print(\"F1-Score:\", f1_score(y_test, predictions, average=\\'weighted\\'))\\n\\n# Example evaluation with trained model\\nassess_model_performance(trained_model)\\n```\\n\\n## Discussion & Conclusion\\n\\n### Analysis of Results\\n\\n- **Influential Factors**: Identify the most impactful demographic and socioeconomic factors in predicting financial literacy.\\n- **Limitations**: Discuss potential limitations or biases that might affect model accuracy, such as data quality issues or overfitting.\\n\\n### Conclusions\\n\\nSummarize key findings from the research on financial literacy, propose actionable insights based on predictive models for addressing educational gaps among different population segments. Emphasize how tailored interventions could leverage these findings to enhance financial literacy rates.\\n\\n## Appendix/Additional Resources\\n\\n### Supporting Code for Feature Importance Analysis\\n\\n```python\\nfrom sklearn.inspection import permutation_importance\\n\\n# Function to analyze feature importance using permutation importance technique\\ndef feature_impact_analysis(model, X_test):\\n    result = permutation_importance(model, X_test, y_test)\\n    print(result.importances_mean)\\n\\n# Example usage with trained model for feature impact analysis\\nfeature_impact_analysis(trained_model, X_test)\\n```\\n\\n### Data Sources\\n\\n- **Dataset 1**: National Financial Capability Study (NFCS) by the Bureau of Labor Statistics. Available at [BLS.gov](https://www.bls.gov/data/).\\n- **Dataset 2**: Survey of Consumer Finances (SCF) by Federal Reserve Board. Accessible through [FRB.org](https://www.federalreserve.gov/publications/).\\n\\nThese resources are crucial for collecting comprehensive data that includes detailed information on demographics, financial literacy scores, and socioeconomic indicators essential for conducting a thorough research analysis.\\n\\n---\\n\\n\\nThis document provides an enhanced version of the initial draft by structuring it into distinct sections (Overview, Methodology, Code Snippets, Results & Evaluation, Discussion & Conclusion, Appendix), each with its specific focus area. The revised format ensures that readers can easily navigate through the project\\'s objectives, methodologies employed, results analyzed, and implications discussed in detail.\\n\\n---\\nSolution 2 (temp=0.71):\\n---\\n\\n\\n## **Financial Literacy Research Using Machine Learning**\\n\\n\\n### Overview\\n\\nThis project is designed to develop a predictive model leveraging machine learning algorithms with the aim of classifying individuals based on their level of financial literacy and forecasting risk associated with poor financial decision-making.\\n\\n### Project Title: Research on Financial Literacy Using Machine Learning\\n\\n#### Problem Statement:\\n\\nMany individuals face challenges due to insufficient knowledge and skills in managing finances, which can lead to instability and vulnerability. The project aims to address this issue by creating an accurate predictive model that can identify varying levels of financial literacy among different population groups.\\n\\n### Methodology\\n\\n\\n#### **Data & Methods**\\n\\n**Data Sources:**\\nThe research utilizes publicly available datasets such as the National Financial Capability Study (NFCS) from the Bureau of Labor Statistics and the Survey of Consumer Finances (SCF) by the Federal Reserve Board. These datasets provide comprehensive information on demographics, financial literacy scores, income levels, education level, etc.\\n\\n**Data Preprocessing:**\\n- **Encoding:** Categorical variables are encoded using techniques like one-hot encoding or label encoding.\\n- **Handling Missing Values:** Missing data is managed through imputation methods such as mean, median, or mode.\\n- **Feature Creation:** New features might be created based on domain knowledge to enhance model performance.\\n\\n#### Code Snippets\\n\\n```python\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\n\\ndata = pd.read_csv(\\'financial_literacy_data.csv\\')\\n\\nfeatures = [\\'age\\', \\'education_level\\', \\'income\\']\\ntarget = \\'financial_literacy_score\\'\\n\\nX = data[features]\\ny = data[target]\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\\n```\\n\\n\\n### Results & Evaluation\\n\\n#### Results Overview:\\n\\n- **Accuracy:** Percentage of correctly classified instances across different financial literacy levels.\\n- **Precision:** Model\\'s accuracy in predicting high financial literacy cases.\\n- **Recall:** Model\\'s ability to capture all positive (highly literate) cases.\\n- **F1-Score:** Balanced measure of precision and recall.\\n\\n#### Evaluation Metrics\\n\\n```python\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\\n\\n\\ndef evaluate_model(model):\\n    predictions = model.predict(X_test)\\n    print(\"Accuracy:\", accuracy_score(y_test, predictions))\\n    print(\"Precision:\", precision_score(y_test, predictions))\\n    print(\"Recall:\", recall_score(y_test, predictions))\\n    print(\"F1-Score:\", f1_score(y_test, predictions))\\n\\n# Example evaluation with trained model\\nevaluate_model(trained_model)\\n```\\n\\n\\n### Discussion & Conclusion\\n\\n#### Discussion:\\n\\nThe project\\'s predictive model offers insights into the most influential factors contributing to financial literacy. It also highlights potential limitations that might affect its accuracy or generalizability.\\n\\n#### Conclusion:\\n\\nSummarizing key findings gained from researching financial literacy drivers, this work proposes tailored educational interventions aimed at addressing identified risk factors based on the outcomes of machine learning predictions.\\n\\n\\n### Appendix/Additional Resources\\n\\n#### Supporting Code:\\n\\n```python\\nfrom sklearn.inspection import permutation_importance\\n\\ndef permutation_importance_analysis(model, X_test):\\n    result = permutation_importance(model, X_test, y_test)\\n    print(result.importances_mean)\\n\\n# Example usage with trained model\\npermutation_importance_analysis(trained_model, X_test)\\n```\\n\\n#### Data Sources:\\n\\n- **Dataset 1:** National Financial Capability Study (NFCS) by the Bureau of Labor Statistics. [BLS.gov](https://www.bls.gov/data/)\\n- **Dataset 2:** Survey of Consumer Finances (SCF) by Federal Reserve Board. [FRB.org](https://www.federalreserve.gov/publications/)\\n\\nThese resources provide essential datasets that include detailed information necessary for conducting the research and enhancing model accuracy through comprehensive analysis.\\n\\n---\\n\\n---\\nSolution 3 (temp=0.77):\\n### Project Report: Financial Literacy Research Using Machine Learning\\n\\n#### Overview\\nThis project aims to develop a predictive model using machine learning algorithms that accurately classifies individuals based on their level of financial literacy and predicts the risk levels associated with poor financial decisions.\\n\\n#### Project Title: Research on Financial Literacy Using Machine Learning\\n\\n#### Problem Statement:\\nMany individuals lack fundamental knowledge and skills necessary for making informed financial decisions. This lack can lead to potential financial instability, posing significant risks in personal finance management.\\n\\n#### Goal:\\nTo develop a predictive model capable of identifying individuals with varying degrees of financial literacy.\\n\\n#### Scope:\\nThe research focuses on a specific population group (e.g., young adults, low-income communities) as the primary data source, without including full deployment or intervention programs.\\n\\n#### Methodology\\n\\n##### Data & Methods\\n**Data Sources:**\\n- Utilize publicly available datasets containing demographic information, socioeconomic indicators such as income and education level, along with financial literacy assessments:\\n  - National Financial Capability Study (NFCS) by the Bureau of Labor Statistics.\\n  - Survey of Consumer Finances (SCF) by Federal Reserve Board.\\n\\n**Data Preprocessing:**\\n- Prepare data for machine learning algorithms using techniques like:\\n  - **One-hot encoding** or **label encoding** for categorical variables.\\n  - Handling missing values through imputation methods such as mean, median, or mode.\\n  - Creating new features based on domain expertise.\\n\\n#### Code Snippets\\n```python\\n# Import necessary libraries (e.g., pandas, scikit-learn)\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load and preprocess the dataset using pandas\\ndata = pd.read_csv(\\'financial_literacy_data.csv\\')\\n\\n# Define features (X) and target variable (y)\\nfeatures = [\\'age\\', \\'education_level\\', \\'income\\']\\ntarget = \\'financial_literacy_score\\'\\n\\nX = data[features]\\ny = data[target]\\n\\n# Splitting the dataset into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\\n```\\n\\n#### Results & Evaluation\\n\\n**Results Overview:**\\n- **Accuracy**: Percentage of correctly classified instances across different financial literacy levels.\\n- Precision: Model\\'s ability to accurately predict high financial literacy cases.\\n- Recall: Model\\'s capability to capture all positive (highly literate) cases.\\n- F1-Score: Balanced precision and recall for a comprehensive performance metric.\\n\\n**Evaluation Metrics**\\n```python\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\\n\\n# Function to evaluate model performance\\ndef evaluate_model(model):\\n    predictions = model.predict(X_test)\\n    print(\"Accuracy:\", accuracy_score(y_test, predictions))\\n    print(\"Precision:\", precision_score(y_test, predictions))\\n    print(\"Recall:\", recall_score(y_test, predictions))\\n    print(\"F1-Score:\", f1_score(y_test, predictions))\\n\\n# Example evaluation with trained model\\nevaluate_model(trained_model)\\n```\\n\\n#### Discussion & Conclusion\\n\\n**Discussion:**\\n- Interpret the results of the predictive model to discuss the most influential factors contributing to financial literacy.\\n- Analyze potential limitations that may affect accuracy or generalizability.\\n\\n**Conclusion:**\\nSummarize key insights gained from the research on financial literacy drivers and propose future directions for addressing educational gaps through tailored interventions based on identified risk factors.\\n\\n#### Appendix/Additional Resources\\n\\n**Supporting Code:**\\n```python\\n# Additional code for feature importance analysis using permutation importance\\nfrom sklearn.inspection import permutation_importance\\n\\ndef permutation_importance_analysis(model, X_test):\\n    result = permutation_importance(model, X_test, y_test)\\n    print(result.importances_mean)\\n\\n# Example usage with trained model\\npermutation_importance_analysis(trained_model, X_test)\\n```\\n\\n**Data Sources:**\\n- **Dataset 1:** National Financial Capability Study (NFCS) by the Bureau of Labor Statistics. Accessible at [BLS.gov](https://www.bls.gov/data/).\\n- **Dataset 2:** Survey of Consumer Finances (SCF) by Federal Reserve Board. Accessible at [FRB.org](https://www.federalreserve.gov/publications/).\\n\\nThese resources provide comprehensive datasets that include detailed information on demographics, financial literacy scores, and socioeconomic indicators necessary for conducting the research.\\n\\n\\n---\\nThis project report provides a structured overview of the methodology, results evaluation process, discussion points for conclusions, and additional supporting resources. It ensures transparency and comprehensiveness in detailing the machine learning approach to assessing financial literacy across specific population groups.\\n\\n\\n# **Professional AI-Driven Selection Prompt for Full Project Report with Emphasis on \\'Results & Evaluation\\'**\\n\\n## **Objective**\\n\\nYou are an advanced AI-driven technical report generator responsible for producing a **fully structured, highly professional, and insight-driven** comprehensive project report. While the **primary focus** is to meticulously refine and finalize the **\\'Results & Evaluation\\'** section, you must also ensure that all **preceding sections** (such as Project Overview, Data & Methodologies) are written at a professional standard, maintaining clarity, accuracy, and logical coherence. The entire report must align with industry standards, ensuring structured documentation, seamless readability, and technically sound content.\\n\\n---\\n\\n## **Step 1: AI Thought Process & Understanding**\\n\\nBefore selecting the best version, analyze the **purpose and key requirements** of the full report, with a primary focus on the \\'Results & Evaluation\\' section:\\n\\n- How should the **Project Overview** and **Data & Methodologies** be refined to support the analysis in the \\'Results & Evaluation\\' section?\\n- What key findings must be clearly communicated in \\'Results & Evaluation\\'?\\n- Which evaluation metrics best demonstrate the project\\'s success?\\n- How can results be structured for clarity, impact, and ease of interpretation?\\n- What formatting and technical presentation enhance readability and engagement?\\n\\nUse these insights to guide the **selection and refinement** process for the entire report.\\n\\n---\\n\\n## **Step 2: Candidate Version Generation**\\n\\nThree different candidate versions of the \\'Results & Evaluation\\' section have been generated, each varying in depth, structure, and formatting. \\n\\nEach version includes:\\n\\n### **2.1 Results Summary**\\n- Key insights and findings from the project.\\n- Trends, anomalies, or expected vs. actual results.\\n- Alignment with project objectives and goals.\\n\\n### **2.2 Evaluation Metrics**\\n- Explanation and justification of accuracy, precision, recall, F1-score, RMSE, etc.\\n- Appropriate selection of metrics based on project requirements.\\n- Clarity in how these metrics validate the effectiveness of the project.\\n\\n### **2.3 Data Visualization & Code Blocks**\\n- Markdown-formatted code blocks for **result computation and metric evaluation**.\\n- Placeholder references for figures, tables, or charts where necessary.\\n\\n#### **Example Code for Evaluating Model Performance:**\\n```python\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\\n\\ny_true = [0, 1, 1, 0, 1, 0, 1]\\ny_pred = [0, 1, 0, 0, 1, 1, 1]\\n\\nmetrics = {\\n    \"Accuracy\": accuracy_score(y_true, y_pred),\\n    \"Precision\": precision_score(y_true, y_pred),\\n    \"Recall\": recall_score(y_true, y_pred),\\n    \"F1 Score\": f1_score(y_true, y_pred)\\n}\\n\\nfor metric, value in metrics.items():\\n    print(f\"{metric}: {value:.2f}\")\\n```\\n\\n---\\n\\n## **Step 3: AI-Based Comparative Evaluation & Selection**\\n\\nCompare the **three generated versions** based on the following criteria:\\n\\n### **3.1 Clarity & Readability**\\n- Which version **best communicates** key findings and insights?\\n- Does the tone maintain **technical accuracy while remaining accessible**?\\n\\n### **3.2 Comprehensiveness**\\n- Does the version include a **thorough explanation** of results and evaluation?\\n- Are all necessary evaluation metrics **fully justified**?\\n\\n### **3.3 Logical Flow & Structure**\\n- Does the version transition **smoothly** from presenting results to evaluating them?\\n- Are the sections organized **in a logical and professional format**?\\n\\n### **3.4 Technical Accuracy & Presentation**\\n- Is the Markdown formatting **clear, professional, and consistent**?\\n- Are visual elements and code blocks **well-integrated and effective**?\\n\\n#### **Final Decision:**\\nSelect the **best** version based on the **highest overall quality** without referencing the comparison process or alternative drafts.\\n\\n---\\n\\n## **Step 4: Final Refinement & Output Generation**\\n\\nOnce the best version has been selected, apply **final refinements** to ensure that:\\n- The **Project Overview** and **Data & Methodologies** sections are professionally structured and logically support the \\'Results & Evaluation\\' section.\\n- The \\'Results & Evaluation\\' section is **polished, structured, and logically coherent**.\\n- Formatting, syntax, and transitions **meet professional documentation standards**.\\n- Any **necessary improvements** are made without disrupting the original intent of the section.\\n\\n---\\n\\n## **Final Output**\\n\\nGenerate the **full project report**, ensuring that all sections maintain professional consistency. The **primary focus** should be on finalizing the **\\'Results & Evaluation\\'** section to the highest standard, while also ensuring that preceding sections are professionally written and aligned with the reportâ€™s findings.\\n\\n### **Key Deliverables:**\\n- **A single, refined** full report, including **professionally structured** Project Overview, Data & Methodologies, and **the best** \\'Results & Evaluation\\' section.\\n- **Integration of the strongest aspects** from all evaluated versions.\\n- **Accurate, justified evaluation metrics** that align with project objectives.\\n- **Clear Markdown formatting** for readability and professional presentation.\\n\\n---\\n\\n## **Task Directive**\\n\\nYour task is to **think autonomously and critically** about the best way to refine and present the **full project report**. While the main focus is on \\'Results & Evaluation,\\' all preceding sections must also be written at a **high professional standard** to ensure consistency and seamless flow.\\n\\n**Generate the final project report with a primary focus on ensuring that the \\'Results & Evaluation\\' section meets the highest professional standards, while maintaining excellence across all preceding sections.**\\n\\n'}]}\n",
      "===== SELF-CONSISTENCY BEST SOLUTION =====\n",
      "---\n",
      "\n",
      "# Project Report: Analyzing the Performance of a Model for Predicting Consumer Purchases\n",
      "\n",
      "## **Project Overview**\n",
      "\n",
      "Our goal is to develop a predictive model capable of forecasting consumer purchasing behavior based on various factors such as demographic data, past purchase history, and online activity. We employed a comprehensive dataset containing detailed information about millions of users across different industries and products.\n",
      "\n",
      "The methodology involved a rigorous feature selection process followed by the application of multiple machine learning algorithms to ensure robustness in prediction accuracy and reliability. This report focuses on presenting key findings, evaluation metrics, and an interpretation of how these metrics contribute to understanding the model's performance.\n",
      "\n",
      "## **Data & Methodologies**\n",
      "\n",
      "We utilized datasets from diverse sources including e-commerce platforms, online behavior logs, and customer surveys to create a comprehensive data pool for training our predictive models. The methodologies included feature engineering to extract meaningful insights, handling missing data through imputation techniques, and rigorous cross-validation protocols to ensure model generalizability.\n",
      "\n",
      "The primary machine learning algorithms used were Random Forests, Gradient Boosting Machines (GBM), and Neural Networks due to their proven effectiveness in handling high-dimensional datasets with complex relationships. These models were trained using an iterative process that adjusted parameters based on performance indicators like accuracy, precision, recall, and F1-score.\n",
      "\n",
      "## **Results Summary**\n",
      "\n",
      "The evaluation of our predictive model has revealed significant insights into consumer behavior prediction capabilities:\n",
      "\n",
      "- **Random Forests** achieved the highest overall accuracy (85%) with a balanced precision/recall ratio across different demographic segments.\n",
      "- Gradient Boosting Machines (GBM) showed superior recall rates for rare purchase events, making it ideal for targeting promotional activities.\n",
      "- Neural Networks excelled in feature importance extraction, identifying key influencers of purchasing behavior.\n",
      "\n",
      "### **Evaluation Metrics**\n",
      "\n",
      "The evaluation metrics were selected based on their ability to provide a holistic view of the model's performance:\n",
      "\n",
      "1. **Accuracy** was used to measure the overall correctness of predictions across all classes, indicating how well our model can distinguish between non-purchasing and purchasing consumers.\n",
      "2. **Precision** measures the proportion of true positives among all positive predictions, highlighting GBMâ€™s effectiveness in accurately identifying potential buyers with high confidence.\n",
      "3. **Recall** focuses on capturing true positives while minimizing false negatives, ensuring we do not miss out on marketing opportunities for underrepresented segments.\n",
      "4. **F1 Score**, a harmonic mean of precision and recall, provides a balanced measure that is particularly useful when dealing with imbalanced datasets.\n",
      "\n",
      "### **Code Block: Evaluating Model Performance**\n",
      "\n",
      "```python\n",
      "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
      "\n",
      "# Assuming y_true contains the true labels and y_pred contains predictions from our model\n",
      "y_true = [0, 1, 1, 0, 1, 0, 1] # Non-purchasing vs. purchasing consumers\n",
      "y_pred = [0, 1, 0, 0, 1, 1, 1] \n",
      "\n",
      "# Metrics calculation for the model predictions\n",
      "metrics = {\n",
      "    \"Accuracy\": accuracy_score(y_true, y_pred),\n",
      "    \"Precision\": precision_score(y_true, y_pred),\n",
      "    \"Recall\": recall_score(y_true, y_pred),\n",
      "    \"F1 Score\": f1_score(y_true, y_pred)\n",
      "}\n",
      "\n",
      "for metric, value in metrics.items():\n",
      "    print(f\"{metric}: {value:.2f}\")\n",
      "```\n",
      "\n",
      "## **Data Visualization**\n",
      "\n",
      "To enhance the interpretability of our findings, we have included visualizations such as confusion matrices for each model type and feature importance plots using bar charts to illustrate which factors most significantly impact purchasing decisions.\n",
      "\n",
      "### Confusion Matrix:\n",
      "- **Random Forests**: [450 True Negatives (Non-Purchasers), 120 True Positives (Purchasers), 30 False Positives, 22 False Negatives]\n",
      "  \n",
      "- **Gradient Boosting Machines**: [445 True Negatives, 135 True Positives, 25 False Positives, 10 False Negatives]\n",
      "\n",
      "- **Neural Networks**: [465 True Negatives, 110 True Positives, 15 False Positives, 18 False Negatives]\n",
      "\n",
      "### Feature Importance:\n",
      "Bar charts showing the relative importance of features like age range, income level, frequency of online browsing, and specific product category preferences are provided to highlight influential factors.\n",
      "\n",
      "## **Conclusion**\n",
      "\n",
      "The developed predictive models offer significant advancements in consumer behavior forecasting. With the combination of Random Forests for overall accuracy, GBM for recall on rare events, and Neural Networks for feature extraction, our model provides a powerful tool for personalized marketing strategies and customer insights.\n",
      "\n",
      "Further refinement could focus on incorporating real-time data streams to enhance predictions, potentially improving the balance between precision and recall further by leveraging more up-to-date information about consumer behavior.\n",
      "\n",
      "Time taken for best-solution analysis: 22.697s\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "## SELF-CONSISTENCY PROMPTING: PROJECT OVERVIEW\n",
    "############################################################\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "from datetime import datetime\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "# 1) Read the last response from the chain-of-thought logs CSV file\n",
    "with open(\"data/chain_of_thought_logs.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    chain_of_thought_output = list(reader)[-1][5]  # Assuming the response is in the sixth column\n",
    "\n",
    "# 2) Define a base prompt for multiple solutions\n",
    "BASE_PROMPT = f\"\"\"\n",
    "You are an advanced AI-driven technical writing system tasked with generating a **fully structured, high-quality, and professional technical report** in Markdown format. Your primary objective is to **refine and finalize a comprehensive project report** with a particular emphasis on the **'Results & Evaluation'** section. \n",
    "\n",
    "While the **main goal** is to ensure that the 'Results & Evaluation' section is the most insightful, technically sound, and well-structured, you must also maintain **a professional and logically coherent structure** across all preceding sections, including:\n",
    "- **Project Overview** (Concise introduction to the project)\n",
    "- **Data & Methodologies** (Thorough explanation of data collection, preprocessing, and analytical techniques)\n",
    "- **Results & Evaluation** (Detailed insights, performance metrics, visualizations, and structured technical analysis)\n",
    "\n",
    "The **final output** must be a **refined, high-quality, and structured Markdown-formatted report** that effectively conveys all essential information, ensuring seamless readability, technical precision, and a structured presentation.\n",
    "\n",
    "---\n",
    "\n",
    "## **Guidelines for Refinement**\n",
    "\n",
    "### **1. Maintain Professional Quality Across All Sections**\n",
    "- **Project Overview:** Ensure clarity, conciseness, and strong introduction of key objectives.\n",
    "- **Data & Methodologies:** Present structured explanations of data sources, preprocessing, and analytical techniques.\n",
    "- **Results & Evaluation:** Provide detailed insights, structured performance analysis, and well-integrated code blocks.\n",
    "\n",
    "### **2. Generate & Compare Multiple Versions of 'Results & Evaluation'**\n",
    "- Generate **three distinct versions** of the 'Results & Evaluation' section, each varying in structure, depth, and formatting.\n",
    "- Each version must contain:\n",
    "  - **Results Summary:** Main findings, trends, and anomalies.\n",
    "  - **Evaluation Metrics:** Accuracy, precision, recall, F1-score, RMSE, etc.\n",
    "  - **Data Visualizations:** Tables, figures, and structured charts.\n",
    "  - **Code Blocks:** Performance analysis and metric computation.\n",
    "\n",
    "### **3. Select and Refine the Best Version**\n",
    "- Compare the versions using these criteria:\n",
    "  - **Clarity & Readability:** Structured and easy to comprehend.\n",
    "  - **Comprehensiveness:** Coverage of all relevant findings.\n",
    "  - **Logical Flow:** Smooth transitions from results to evaluation.\n",
    "  - **Technical Accuracy:** Correct calculations, visualizations, and justifications.\n",
    "- Select the **best version** and refine it to meet the highest professional standards.\n",
    "\n",
    "### **4. Apply Final Refinements to the Entire Report**\n",
    "- Ensure the **Project Overview** and **Data & Methodologies** sections are logically structured and polished.\n",
    "- Format the report with:\n",
    "  - **Proper Markdown headings, bullet points, structured tables, and code blocks.**\n",
    "  - **Consistent, structured, and professional content presentation.**\n",
    "\n",
    "---\n",
    "\n",
    "## **Final Output Requirements**\n",
    "\n",
    "Generate a **fully structured and professional final report** in Markdown format with:\n",
    "- **A well-structured Project Overview** that provides context and introduces key objectives.\n",
    "- **A professionally refined Data & Methodologies section** that aligns with findings in 'Results & Evaluation'.\n",
    "- **The most polished 'Results & Evaluation' section**, integrating the strongest aspects of the different candidate versions.\n",
    "- **Properly formatted code blocks and visual elements** for readability and technical precision.\n",
    "\n",
    "### **Final Deliverables:**\n",
    "- The **full project report**, ensuring a **highly polished 'Results & Evaluation'** while maintaining professional quality across all preceding sections.\n",
    "- **Clear Markdown formatting** with structured documentation, tables, figures, and code blocks.\n",
    "- **Seamless logical flow** between all sections, ensuring high readability and comprehension.\n",
    "\n",
    "---\n",
    "\n",
    "## **Task Directive**\n",
    "\n",
    "Your task is to **generate the full project report**, ensuring **all sections meet professional documentation standards**, with an explicit focus on refining and finalizing the 'Results & Evaluation' section to the highest level of quality.\n",
    "\n",
    "**Produce a final, fully polished Markdown-formatted report that aligns with professional and industry standards.**\n",
    "\n",
    "\n",
    "{chain_of_thought_output}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 3) Generate multiple solutions\n",
    "def generate_solutions(prompt, model_name=\"qwen2\", num_solutions=3):\n",
    "    \"\"\"\n",
    "    Creates multiple solutions by calling the model multiple times\n",
    "    with slight variations (e.g., random temperature).\n",
    "    \"\"\"\n",
    "    solutions = []\n",
    "    for i in range(num_solutions):\n",
    "        # Optionally vary temperature slightly\n",
    "        temp = round(random.uniform(0.6, 0.8), 2)\n",
    "        payload = create_payload(\n",
    "            target=\"open-webui\",\n",
    "            model=model_name,\n",
    "            prompt=prompt,\n",
    "            temperature=temp,\n",
    "            num_ctx=150,\n",
    "            num_predict=200\n",
    "        )\n",
    "        time_taken, response = model_req(payload=payload)\n",
    "        solutions.append({\n",
    "            \"attempt\": i + 1,\n",
    "            \"temperature\": temp,\n",
    "            \"time_taken\": time_taken,\n",
    "            \"response\": response\n",
    "        })\n",
    "    return solutions\n",
    "\n",
    "# 4) Self-consistency check: re-prompt the model to choose the best solution\n",
    "def pick_best_solution(solutions, model_name=\"qwen2\"):\n",
    "    \"\"\"\n",
    "    Sends all solutions back to the model, asking it to pick the best one.\n",
    "    \"\"\"\n",
    "    # Build a comparison prompt\n",
    "    comparison_prompt = \"Below are several candidate outputs for the Project Overview:\\n\\n\"\n",
    "    for s in solutions:\n",
    "        comparison_prompt += f\"---\\nSolution {s['attempt']} (temp={s['temperature']}):\\n{s['response']}\\n\\n\"\n",
    "    comparison_prompt += \"\"\"\n",
    "# **Professional AI-Driven Selection Prompt for Full Project Report with Emphasis on 'Results & Evaluation'**\n",
    "\n",
    "## **Objective**\n",
    "\n",
    "You are an advanced AI-driven technical report generator responsible for producing a **fully structured, highly professional, and insight-driven** comprehensive project report. While the **primary focus** is to meticulously refine and finalize the **'Results & Evaluation'** section, you must also ensure that all **preceding sections** (such as Project Overview, Data & Methodologies) are written at a professional standard, maintaining clarity, accuracy, and logical coherence. The entire report must align with industry standards, ensuring structured documentation, seamless readability, and technically sound content.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 1: AI Thought Process & Understanding**\n",
    "\n",
    "Before selecting the best version, analyze the **purpose and key requirements** of the full report, with a primary focus on the 'Results & Evaluation' section:\n",
    "\n",
    "- How should the **Project Overview** and **Data & Methodologies** be refined to support the analysis in the 'Results & Evaluation' section?\n",
    "- What key findings must be clearly communicated in 'Results & Evaluation'?\n",
    "- Which evaluation metrics best demonstrate the project's success?\n",
    "- How can results be structured for clarity, impact, and ease of interpretation?\n",
    "- What formatting and technical presentation enhance readability and engagement?\n",
    "\n",
    "Use these insights to guide the **selection and refinement** process for the entire report.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 2: Candidate Version Generation**\n",
    "\n",
    "Three different candidate versions of the 'Results & Evaluation' section have been generated, each varying in depth, structure, and formatting. \n",
    "\n",
    "Each version includes:\n",
    "\n",
    "### **2.1 Results Summary**\n",
    "- Key insights and findings from the project.\n",
    "- Trends, anomalies, or expected vs. actual results.\n",
    "- Alignment with project objectives and goals.\n",
    "\n",
    "### **2.2 Evaluation Metrics**\n",
    "- Explanation and justification of accuracy, precision, recall, F1-score, RMSE, etc.\n",
    "- Appropriate selection of metrics based on project requirements.\n",
    "- Clarity in how these metrics validate the effectiveness of the project.\n",
    "\n",
    "### **2.3 Data Visualization & Code Blocks**\n",
    "- Markdown-formatted code blocks for **result computation and metric evaluation**.\n",
    "- Placeholder references for figures, tables, or charts where necessary.\n",
    "\n",
    "#### **Example Code for Evaluating Model Performance:**\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_true = [0, 1, 1, 0, 1, 0, 1]\n",
    "y_pred = [0, 1, 0, 0, 1, 1, 1]\n",
    "\n",
    "metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "    \"Precision\": precision_score(y_true, y_pred),\n",
    "    \"Recall\": recall_score(y_true, y_pred),\n",
    "    \"F1 Score\": f1_score(y_true, y_pred)\n",
    "}\n",
    "\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.2f}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 3: AI-Based Comparative Evaluation & Selection**\n",
    "\n",
    "Compare the **three generated versions** based on the following criteria:\n",
    "\n",
    "### **3.1 Clarity & Readability**\n",
    "- Which version **best communicates** key findings and insights?\n",
    "- Does the tone maintain **technical accuracy while remaining accessible**?\n",
    "\n",
    "### **3.2 Comprehensiveness**\n",
    "- Does the version include a **thorough explanation** of results and evaluation?\n",
    "- Are all necessary evaluation metrics **fully justified**?\n",
    "\n",
    "### **3.3 Logical Flow & Structure**\n",
    "- Does the version transition **smoothly** from presenting results to evaluating them?\n",
    "- Are the sections organized **in a logical and professional format**?\n",
    "\n",
    "### **3.4 Technical Accuracy & Presentation**\n",
    "- Is the Markdown formatting **clear, professional, and consistent**?\n",
    "- Are visual elements and code blocks **well-integrated and effective**?\n",
    "\n",
    "#### **Final Decision:**\n",
    "Select the **best** version based on the **highest overall quality** without referencing the comparison process or alternative drafts.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 4: Final Refinement & Output Generation**\n",
    "\n",
    "Once the best version has been selected, apply **final refinements** to ensure that:\n",
    "- The **Project Overview** and **Data & Methodologies** sections are professionally structured and logically support the 'Results & Evaluation' section.\n",
    "- The 'Results & Evaluation' section is **polished, structured, and logically coherent**.\n",
    "- Formatting, syntax, and transitions **meet professional documentation standards**.\n",
    "- Any **necessary improvements** are made without disrupting the original intent of the section.\n",
    "\n",
    "---\n",
    "\n",
    "## **Final Output**\n",
    "\n",
    "Generate the **full project report**, ensuring that all sections maintain professional consistency. The **primary focus** should be on finalizing the **'Results & Evaluation'** section to the highest standard, while also ensuring that preceding sections are professionally written and aligned with the reportâ€™s findings.\n",
    "\n",
    "### **Key Deliverables:**\n",
    "- **A single, refined** full report, including **professionally structured** Project Overview, Data & Methodologies, and **the best** 'Results & Evaluation' section.\n",
    "- **Integration of the strongest aspects** from all evaluated versions.\n",
    "- **Accurate, justified evaluation metrics** that align with project objectives.\n",
    "- **Clear Markdown formatting** for readability and professional presentation.\n",
    "\n",
    "---\n",
    "\n",
    "## **Task Directive**\n",
    "\n",
    "Your task is to **think autonomously and critically** about the best way to refine and present the **full project report**. While the main focus is on 'Results & Evaluation,' all preceding sections must also be written at a **high professional standard** to ensure consistency and seamless flow.\n",
    "\n",
    "**Generate the final project report with a primary focus on ensuring that the 'Results & Evaluation' section meets the highest professional standards, while maintaining excellence across all preceding sections.**\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    payload_compare = create_payload(\n",
    "        target=\"open-webui\",\n",
    "        model=model_name,\n",
    "        prompt=comparison_prompt,\n",
    "        temperature=0.7,\n",
    "        num_ctx=250,\n",
    "        num_predict=300\n",
    "    )\n",
    "    time_compare, response_compare = model_req(payload=payload_compare)\n",
    "    return time_compare, response_compare\n",
    "\n",
    "# 5) Generate multiple solutions\n",
    "solutions = generate_solutions(BASE_PROMPT, model_name=\"qwen2\", num_solutions=3)\n",
    "\n",
    "# 6) Ask the model to pick the best solution\n",
    "time_best, best_solution_response = pick_best_solution(solutions, model_name=\"qwen2\")\n",
    "\n",
    "# 7) Print out the final recommended solution\n",
    "print(\"===== SELF-CONSISTENCY BEST SOLUTION =====\")\n",
    "print(best_solution_response)\n",
    "if time_best:\n",
    "    print(f\"\\nTime taken for best-solution analysis: {time_best}s\")\n",
    "\n",
    "# 8) (Optional) Log solutions and best pick\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Log each solution\n",
    "with open(\"data/self_consistency_solutions.csv\", \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Optionally write a header row if needed:\n",
    "    # writer.writerow([\"timestamp\", \"attempt\", \"temperature\", \"time_taken\", \"response\"])\n",
    "    for s in solutions:\n",
    "        writer.writerow([\n",
    "            datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            s[\"attempt\"],\n",
    "            s[\"temperature\"],\n",
    "            s[\"time_taken\"],\n",
    "            s[\"response\"].replace(\"\\n\", \"\\\\n\")\n",
    "        ])\n",
    "\n",
    "# Log the best solution\n",
    "with open(\"data/self_consistency_best.csv\", \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\n",
    "        datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"best_solution\",\n",
    "        time_best,\n",
    "        best_solution_response.replace(\"\\n\", \"\\\\n\")\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
